{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1632899a-43ec-4a56-8ab7-7cbfda0261e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818d89ff-7698-463a-beca-cd9e4025f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 22:59:14.251157: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-30 22:59:14.298689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-30 22:59:14.298806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-30 22:59:14.301025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-30 22:59:14.314228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-30 22:59:15.088398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf4414f-5852-462e-a703-d0fe892831e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5974b777-ee4d-4eeb-8c82-e68e0f04340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e1cf7a-2136-474d-86fc-746c26e98500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 22:59:16.255740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "## CHECK GPU\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb24c5ad-aaf6-4354-8641-19a5b3c2ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6350537c-20f4-4443-a852-3760d99e0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS DEFINITION\n",
    "\n",
    "#READ SPLIT TOKENS\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing value {val}: {e}\")\n",
    "        return val  # Return the original value if there is an error\n",
    "\n",
    "#MERGE TOKENS AS A WHOLE TEXT\n",
    "def join_tokens(token_list):\n",
    "    if isinstance(token_list, list):\n",
    "        return ' '.join(token_list)\n",
    "    return token_list\n",
    "\n",
    "\n",
    "#SPLIT TRAIN + TEST 80-20\n",
    "def split_train_test(df, label_name):\n",
    "    train, test= train_test_split(df, test_size=0.2, stratify=df[label_name],random_state=42)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73e59c91-abb7-4179-ae48-144a4528ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def precision_m(y_true, y_pred):     \n",
    "    y_pred = tf.nn.sigmoid(y_pred)  # Apply sigmoid to get probabilities   \n",
    "    y_pred = K.round(y_pred)  # Convert probabilities to 0 or 1    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))     \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))     \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())     \n",
    "    return precision\n",
    "\n",
    "# Custom metric for recall\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_pred = tf.nn.sigmoid(y_pred)  # Apply sigmoid to get probabilities\n",
    "    y_pred = K.round(y_pred)  # Convert probabilities to 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# Custom metric for F1 score\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "def false_negative_rate_m(y_true, y_pred):\n",
    "    # Apply sigmoid to get probabilities\n",
    "    y_pred = tf.nn.sigmoid(y_pred)\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = K.round(y_pred)\n",
    "    # Calculate False Negatives\n",
    "    false_negatives = K.sum(K.cast(y_true, dtype='float32') * (1 - y_pred))\n",
    "    # Calculate True Positives + False Negatives (total actual positives)\n",
    "    possible_positives = K.sum(K.cast(y_true, dtype='float32'))\n",
    "    # Calculate False Negative Rate\n",
    "    fnr = false_negatives / (possible_positives + K.epsilon())\n",
    "    return fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0743baa8-3261-49a3-81a6-13bc04c42c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData=pd.read_csv(\"../Dataset/datiClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb878e4-99bf-4d45-9c25-611d9ca6d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData=CleanData[[\"clean_review\",\"is_spoiler\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5b6c2b-ad3c-4340-91a2-602c8590a771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>is_spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['oscar', 'year', 'shawshank', 'redemption', '...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['shawshank', 'redemption', 'without', 'doubt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['believe', 'film', 'best', 'story', 'ever', '...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['yes', 'spoiler', 'film', 'emotional', 'impac...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['heart', 'extraordinary', 'movie', 'brilliant...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573908</th>\n",
       "      <td>['go', 'wise', 'fast', 'pure', 'entertainment'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573909</th>\n",
       "      <td>['well', 'shall', 'say', 'one', 'fun', 'rate',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573910</th>\n",
       "      <td>['go', 'best', 'movie', 'ever', 'seen', 'seen'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573911</th>\n",
       "      <td>['call', '1999', 'teenage', 'version', 'pulp',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573912</th>\n",
       "      <td>['movie', 'made', 'doubt', 'sucker', 'family',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573913 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_review  is_spoiler\n",
       "0       ['oscar', 'year', 'shawshank', 'redemption', '...        True\n",
       "1       ['shawshank', 'redemption', 'without', 'doubt'...        True\n",
       "2       ['believe', 'film', 'best', 'story', 'ever', '...        True\n",
       "3       ['yes', 'spoiler', 'film', 'emotional', 'impac...        True\n",
       "4       ['heart', 'extraordinary', 'movie', 'brilliant...        True\n",
       "...                                                   ...         ...\n",
       "573908  ['go', 'wise', 'fast', 'pure', 'entertainment'...       False\n",
       "573909  ['well', 'shall', 'say', 'one', 'fun', 'rate',...       False\n",
       "573910  ['go', 'best', 'movie', 'ever', 'seen', 'seen'...       False\n",
       "573911  ['call', '1999', 'teenage', 'version', 'pulp',...       False\n",
       "573912  ['movie', 'made', 'doubt', 'sucker', 'family',...       False\n",
       "\n",
       "[573913 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22bb9992-8855-4ca4-8b12-68517dd33229",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = CleanData['is_spoiler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc05a7cb-1bdd-4c54-bb9c-9ba871002ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData[\"clean_review\"] = CleanData[\"clean_review\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d6db5b-5f87-40b5-8dd5-358a2f274fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573913 entries, 0 to 573912\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   clean_review  573913 non-null  object\n",
      " 1   is_spoiler    573913 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "CleanData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9781a328-96b2-4ec3-a6a0-05df3400a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData[\"whole__text\"] = CleanData[\"clean_review\"].apply(join_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b8ed58-016a-4669-b1cb-7ba41f3ffeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oscar year shawshank redemption written direct...\n",
       "1    shawshank redemption without doubt one brillia...\n",
       "2    believe film best story ever told film tell ti...\n",
       "3    yes spoiler film emotional impact find hard wr...\n",
       "4    heart extraordinary movie brilliant indelible ...\n",
       "Name: whole__text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = CleanData['whole__text']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27b89b25-585b-4b06-82d8-3e589af797cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData['is_spoiler_numeric'] = np.where(CleanData['is_spoiler'] == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e181ddae-a300-4b00-b90f-e53a65fbb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData = CleanData.rename(columns={'is_spoiler_numeric': 'label','whole__text':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7687f4d3-b467-4b54-88e0-19a0edc957a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(CleanData, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6289031f-6aa0-4e8c-8d58-a14aca880b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['text','label']]\n",
    "test = test[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c962ed85-e197-4139-b8db-40e4c46ae49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 459130 entries, 94625 to 221631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    459130 non-null  object\n",
      " 1   label   459130 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15dfbb86-c7fa-44d9-b607-3b9962f84ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 23:01:15.370802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train['text'].values, tf.string),\n",
    "            tf.cast(train['label'].values, tf.int64)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564d6cc7-a90d-42de-bfc4-cad08e827e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =( \n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train['text'].values, tf.string),\n",
    "            tf.cast(train['label'].values, tf.int64)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29e0215d-98b2-4c0b-992a-44f811a4ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "025b48dc-1ec8-4f3f-91c5-ab187eba6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'maltese falcon film noir based novel title dashiell hammett directed john huston feature humphrey bogart private investigator sam spade mary astor femme fatale client gladys george peter lorre sydney greenstreet co star key supporting role story follows san francisco private detective dealing three unscrupulous adventurer competing obtain jewel encrusted falcon statuette sam spade hard boiled san francisco private eye unscrupulous next guy also adheres personal code honor office spade archer detective agency sweep miss wonderly offer large retainer sam partner mile archer protect someone named floyd thursby detective believe neither miss wonderly story believe money since archer saw first take case later evening shot death mysterious thursby miss wonderly real name turn brigid shaughnessey story continues sam also introduced effeminate joel cairo fat erudite kasper gutman turn brigid cairo gutman international scoundrel involved search foot high jewel encrusted statuette shape falcon though cairo gutman offer spade small fortune find black bird obviously willing commit mayhem murder towards goal gutman example drug spade allows gunsel wilmer kick beat unconscious detective suspenseful labyrinthine brilliantly cast maltese falcon one influential noirs film still tightest sharpest cynical hollywood official deathless classic bracingly tough even post tarantino standard among important influential movie emerge hollywood system significant way contemporary citizen kane action movie sort least implication character always seem keyed right verge erupting violence turning point picture several respect john huston made directorial debut bogart mostly played bad guy last minute substitution george raft must kicking year afterward role made bogart star established trend setting antihero persona classic movie becomes better multiple viewing indeed'\n",
      "label:  1\n"
     ]
    }
   ],
   "source": [
    "for example, label in training_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4272d-a6f6-44be-b03a-437109812dc2",
   "metadata": {},
   "source": [
    "# RNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fc22521-aeb3-4a13-928b-95bec00d0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa9e8092-eb33-4ae0-8c69-6dd78618a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "493a7f86-bef9-44ee-834c-19e3cb740073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ce79ff-4e90-4311-9f51-eeab074b6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(training_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f56b960-103e-4ce6-a94e-bde3c6700eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'movie', 'film', 'one', 'like', 'character', 'time',\n",
       "       'good', 'story', 'see', 'really', 'make', 'great', 'well', 'would',\n",
       "       'scene', 'get', 'even', 'much'], dtype='<U14')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4256916-2a62-4c0c-9a16-b6071580c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "632b22c5-8805-4875-b4b7-9701f36c0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "             metrics=['accuracy',recall_m,precision_m,f1_m,false_negative_rate_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdd05c-4c36-49a3-9236-61b4bbea5471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f334da22-1a4f-492c-9ee5-e61b0b58c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7174/7174 [==============================] - 448s 62ms/step - loss: 0.5059 - accuracy: 0.7574 - recall_m: 0.2324 - precision_m: 0.5580 - f1_m: 0.3104 - false_negative_rate_m: 0.7676\n",
      "Epoch 2/3\n",
      "7174/7174 [==============================] - 428s 60ms/step - loss: 0.4849 - accuracy: 0.7693 - recall_m: 0.2997 - precision_m: 0.6679 - f1_m: 0.3985 - false_negative_rate_m: 0.7003\n",
      "Epoch 3/3\n",
      "6960/7174 [============================>.] - ETA: 12s - loss: 0.4817 - accuracy: 0.7711 - recall_m: 0.3079 - precision_m: 0.6734 - f1_m: 0.4076 - false_negative_rate_m: 0.6921"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782a571-0f88-45cf-b845-ae13bda8e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy values for each epoch:\")\n",
    "for epoch in range(len(history.history['accuracy'])):\n",
    "    accuracy = history.history['accuracy'][epoch]\n",
    "    precision = history.history['precision_m'][epoch]\n",
    "    recall = history.history['recall_m'][epoch]\n",
    "    f1_score = history.history['f1_m'][epoch]\n",
    "    print(f\"Epoch {epoch}: {accuracy} \" f\"recall: {recall} \" f\"precision: {precision} \" f\"f1-score: {f1_score} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab53a3-303b-425a-9d30-b915bbaf4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy_mean = np.mean(history.history['accuracy'])\n",
    "training_precision_mean = np.mean(history.history['precision_m'])\n",
    "training_recall_mean = np.mean(history.history['recall_m'])\n",
    "training_f1_score_mean = np.mean(history.history['f1_m'])\n",
    "\n",
    "print(f\"    Media Training accuracy: {training_accuracy_mean}\")\n",
    "print(f\"    Media Training precision: {training_precision_mean}\")\n",
    "print(f\"    Media Training recall: {training_recall_mean}\")\n",
    "print(f\"    Media Training F1 score: {training_f1_score_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2074d5-6053-4108-bd31-970123dba874",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e6a37-3c2c-4db3-a73a-736274ca406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b3aea-f7c9-45ab-ad37-c813e70aadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
